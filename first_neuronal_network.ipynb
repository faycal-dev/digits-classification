{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deae7611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a55846e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train) , (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd35c473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "274df2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d15a4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adbc1027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dd8742d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x177c574d5e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1130f411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_train[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62532b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# snn le model ne fonction pas autant, il faut centraliser les donn√©s entre 0 et 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a534ce9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "        0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117647,\n",
       "        0.36862745, 0.60392157, 0.66666667, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235294, 0.6745098 ,\n",
       "        0.99215686, 0.94901961, 0.76470588, 0.25098039, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215686, 0.93333333, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.98431373, 0.36470588, 0.32156863,\n",
       "        0.32156863, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882353, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.77647059,\n",
       "        0.71372549, 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31372549, 0.61176471,\n",
       "        0.41960784, 0.99215686, 0.99215686, 0.80392157, 0.04313725,\n",
       "        0.        , 0.16862745, 0.60392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294,\n",
       "        0.62745098, 0.42352941, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764706, 0.94117647,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "        0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.36470588, 0.98823529, 0.99215686, 0.73333333,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.97647059, 0.99215686, 0.97647059,\n",
       "        0.25098039, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980392, 0.71764706, 0.99215686, 0.99215686, 0.81176471,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.58039216, 0.89803922,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.71372549,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882353,\n",
       "        0.83529412, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.77647059, 0.31764706, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058824, 0.85882353, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.76470588, 0.31372549,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568627,\n",
       "        0.6745098 , 0.88627451, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156863, 0.04313725, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333333,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137255, 0.52941176,\n",
       "        0.51764706, 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b5fd0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flattened = X_train.reshape(len(X_train), 28*28)\n",
    "X_test_flattened = X_test.reshape(len(X_test), 28*28)\n",
    "# pour la premiere couche du reseau neuron chaque neuron est un pixel et pour cela on doit transformer le tableau du 2d a une dimention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2743c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flattened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48391346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "       0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117647, 0.36862745, 0.60392157,\n",
       "       0.66666667, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235294, 0.6745098 , 0.99215686, 0.94901961,\n",
       "       0.76470588, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215686, 0.93333333,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.98431373, 0.36470588,\n",
       "       0.32156863, 0.32156863, 0.21960784, 0.15294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.85882353, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.71372549,\n",
       "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31372549, 0.61176471, 0.41960784, 0.99215686, 0.99215686,\n",
       "       0.80392157, 0.04313725, 0.        , 0.16862745, 0.60392157,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "       0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54509804,\n",
       "       0.99215686, 0.74509804, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04313725, 0.74509804, 0.99215686,\n",
       "       0.2745098 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.1372549 , 0.94509804, 0.88235294, 0.62745098,\n",
       "       0.42352941, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31764706, 0.94117647, 0.99215686, 0.99215686, 0.46666667,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "       0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.36470588,\n",
       "       0.98823529, 0.99215686, 0.73333333, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.97647059, 0.99215686,\n",
       "       0.97647059, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.50980392,\n",
       "       0.71764706, 0.99215686, 0.99215686, 0.81176471, 0.00784314,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "       0.58039216, 0.89803922, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.98039216, 0.71372549, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.25882353, 0.83529412, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.31764706,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.67058824, 0.85882353,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.76470588,\n",
       "       0.31372549, 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568627, 0.6745098 ,\n",
       "       0.88627451, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.95686275, 0.52156863, 0.04313725, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53333333, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.83137255, 0.52941176, 0.51764706, 0.0627451 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flattened[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e3a90a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4877 - accuracy: 0.8767\n",
      "Epoch 2/6\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3062 - accuracy: 0.9155\n",
      "Epoch 3/6\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2854 - accuracy: 0.9209\n",
      "Epoch 4/6\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2751 - accuracy: 0.9238\n",
      "Epoch 5/6\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2680 - accuracy: 0.9260\n",
      "Epoch 6/6\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2629 - accuracy: 0.9274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x177c995ba30>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(10, input_shape=(784,), activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_flattened, y_train, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "799732eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 835us/step - loss: 0.2660 - accuracy: 0.9260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2659775912761688, 0.9259999990463257]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_flattened, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3f35607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.5526957e-06, 5.4201046e-11, 1.5751850e-05, 1.2038767e-02,\n",
       "       5.8182968e-07, 8.6172906e-05, 3.5335229e-10, 7.4786866e-01,\n",
       "       4.4820408e-05, 8.7723136e-04], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_predicted = model.predict(X_test_flattened)\n",
    "y_predicted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "121d2877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x177c9c90640>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1636d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_predicted[0])\n",
    "# pour avoir la plus grande valeur de y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c71a85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_labels = [np.argmax(i) for i in y_predicted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f04c79f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = tf.math.confusion_matrix(labels=y_test,predictions=y_predicted_labels)\n",
    "\n",
    "# import seaborn as sn\n",
    "# plt.figure(figsize = (10,7))\n",
    "# sn.heatmap(cm, annot=True, fmt='d')\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d1638d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   2/1875 [..............................] - ETA: 5:06 - loss: 2.2834 - accuracy: 0.1406WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0080s vs `on_train_batch_end` time: 0.3268s). Check your callbacks.\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2881 - accuracy: 0.9191\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1311 - accuracy: 0.9618\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0926 - accuracy: 0.9726\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0728 - accuracy: 0.9777\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0591 - accuracy: 0.9817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x177fd7f23d0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model avec deux coucheches\n",
    "# pour les couches interieur il est preferable d'utiliser relu comme function d'activation\n",
    "model2 = keras.Sequential([\n",
    "    keras.layers.Dense(100, input_shape=(784,), activation='relu'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs/\", histogram_freq=1)\n",
    "\n",
    "model2.fit(X_train_flattened, y_train, epochs=5, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d2750e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 2220), started 0:05:09 ago. (Use '!kill 2220' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1012d753b7fce00d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1012d753b7fce00d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "300497bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0858 - accuracy: 0.9749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0858176127076149, 0.9749000072479248]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test_flattened,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2b1b2bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# juste pour le plaisir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5901258c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3496 - accuracy: 0.1016\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.2997 - accuracy: 0.1001\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3027 - accuracy: 0.0988\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3026 - accuracy: 0.0987\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3026 - accuracy: 0.0987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17806bc2a60>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = keras.Sequential([\n",
    "    keras.layers.Dense(100, input_shape=(784,), activation='relu'),\n",
    "    keras.layers.Dense(10, activation='relu')\n",
    "])\n",
    "\n",
    "model3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model3.fit(X_train_flattened, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9df3178b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "   1/1875 [..............................] - ETA: 0s - loss: 2.3260 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0080s). Check your callbacks.\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4291 - accuracy: 0.8943\n",
      "Epoch 2/6\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1949 - accuracy: 0.9449\n",
      "Epoch 3/6\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1462 - accuracy: 0.9585\n",
      "Epoch 4/6\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1172 - accuracy: 0.9663\n",
      "Epoch 5/6\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0968 - accuracy: 0.9724\n",
      "Epoch 6/6\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0820 - accuracy: 0.9771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x178121d5bb0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = keras.Sequential([\n",
    "    keras.layers.Dense(100, input_shape=(784,), activation='sigmoid'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model2.fit(X_train_flattened, y_train, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ff1d38c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3082 - accuracy: 0.9184\n",
      "Epoch 2/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1343 - accuracy: 0.9613\n",
      "Epoch 3/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0935 - accuracy: 0.9726\n",
      "Epoch 4/6\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0719 - accuracy: 0.9794\n",
      "Epoch 5/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0558 - accuracy: 0.9840\n",
      "Epoch 6/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0444 - accuracy: 0.9880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1781ec4b580>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = keras.Sequential([\n",
    "    keras.layers.Dense(100, input_shape=(784,), activation='tanh'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model4.fit(X_train_flattened, y_train, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ce30367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2388 - accuracy: 0.9306\n",
      "Epoch 2/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0955 - accuracy: 0.9706\n",
      "Epoch 3/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0669 - accuracy: 0.9793\n",
      "Epoch 4/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0498 - accuracy: 0.9840\n",
      "Epoch 5/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0387 - accuracy: 0.9876\n",
      "Epoch 6/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0335 - accuracy: 0.9894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x177c96813a0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = keras.Sequential([\n",
    "    keras.layers.Dense(200, input_shape=(784,), activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model5.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model5.fit(X_train_flattened, y_train, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "078f0880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2954 - accuracy: 0.9251\n",
      "Epoch 2/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0989 - accuracy: 0.9704\n",
      "Epoch 3/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0651 - accuracy: 0.9802\n",
      "Epoch 4/6\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0467 - accuracy: 0.9857\n",
      "Epoch 5/6\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0347 - accuracy: 0.9895\n",
      "Epoch 6/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0262 - accuracy: 0.9918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x177c79a4340>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = keras.Sequential([\n",
    "    keras.layers.Dense(200, input_shape=(784,), activation='relu'),\n",
    "    keras.layers.Dense(100, activation='sigmoid'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model5.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model5.fit(X_train_flattened, y_train, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2fe4fa05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4158 - accuracy: 0.8902\n",
      "Epoch 2/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1553 - accuracy: 0.9540\n",
      "Epoch 3/6\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1042 - accuracy: 0.9690\n",
      "Epoch 4/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0763 - accuracy: 0.9768\n",
      "Epoch 5/6\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0579 - accuracy: 0.9827\n",
      "Epoch 6/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0444 - accuracy: 0.9860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x177c7c740d0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = keras.Sequential([\n",
    "    keras.layers.Dense(200, input_shape=(784,), activation='sigmoid'),\n",
    "    keras.layers.Dense(100, activation='sigmoid'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model5.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model5.fit(X_train_flattened, y_train, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e341515b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3564 - accuracy: 0.8990\n",
      "Epoch 2/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1636 - accuracy: 0.9503\n",
      "Epoch 3/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1109 - accuracy: 0.9664\n",
      "Epoch 4/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0825 - accuracy: 0.9743\n",
      "Epoch 5/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0634 - accuracy: 0.9795\n",
      "Epoch 6/6\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0490 - accuracy: 0.9845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x177c7f3cbb0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = keras.Sequential([\n",
    "    keras.layers.Dense(200, input_shape=(784,), activation='sigmoid'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model5.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model5.fit(X_train_flattened, y_train, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ab84fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2172 - accuracy: 0.9357\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0914 - accuracy: 0.9719\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0661 - accuracy: 0.9798\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0513 - accuracy: 0.9839\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0397 - accuracy: 0.9880\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0337 - accuracy: 0.9891\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0303 - accuracy: 0.9909\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0266 - accuracy: 0.9917\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0219 - accuracy: 0.9929\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0210 - accuracy: 0.9940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x177c8211e50>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = keras.Sequential([\n",
    "    keras.layers.Dense(300, input_shape=(784,), activation='relu'),\n",
    "    keras.layers.Dense(200, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model5.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model5.fit(X_train_flattened, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c9d2f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3045 - accuracy: 0.9203\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0955 - accuracy: 0.9710\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0632 - accuracy: 0.9806\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0433 - accuracy: 0.9870\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0343 - accuracy: 0.9889\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0285 - accuracy: 0.9907\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0225 - accuracy: 0.9927\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0167 - accuracy: 0.9945\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0174 - accuracy: 0.9942\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0138 - accuracy: 0.9957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x177c851f9d0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = keras.Sequential([\n",
    "    keras.layers.Dense(300, input_shape=(784,), activation='relu'),\n",
    "    keras.layers.Dense(200, activation='sigmoid'),\n",
    "    keras.layers.Dense(100, activation='sigmoid'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model5.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model5.fit(X_train_flattened, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ac3aebee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 1.4185 - accuracy: 0.3827\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 0.3803 - accuracy: 0.8810\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 0.1756 - accuracy: 0.95540s - loss:\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 0.1254 - accuracy: 0.96820s - loss: 0.1258 - accuracy: 0.96 - ETA: 0s - loss:\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 42s 22ms/step - loss: 0.0969 - accuracy: 0.9753\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 0.0786 - accuracy: 0.9801\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 49s 26ms/step - loss: 0.0648 - accuracy: 0.9831\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 50s 26ms/step - loss: 0.0554 - accuracy: 0.9858TA: 0s - los\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 0.0482 - accuracy: 0.98720s - loss: 0.0482 \n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 0.0415 - accuracy: 0.9892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x177c970ee50>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = keras.Sequential([\n",
    "    keras.layers.Dense(700, input_shape=(784,), activation='relu'),\n",
    "    keras.layers.Dense(600, activation='sigmoid'),\n",
    "    keras.layers.Dense(500, activation='sigmoid'),\n",
    "    keras.layers.Dense(400, activation='sigmoid'),\n",
    "    keras.layers.Dense(300, activation='sigmoid'),\n",
    "    keras.layers.Dense(200, activation='sigmoid'),\n",
    "    keras.layers.Dense(100, activation='sigmoid'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model5.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model5.fit(X_train_flattened, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaeb7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
